
from CarbonFootPrint import  CodeCarbon
from extensions.GCS_Bucket import write_string_to_gcs
import service
import sys
import json
from datetime import datetime
from pathlib import Path



def get_script_description_prompt(script_description) -> str:
    prompt = f"""

    Generate a terraform script that has following features/specifications: 

    {script_description}.\n
    
    Rules:
    - Make a very simple structure.
    - Output only valid Terraform code in HCL format.
    - No XML/JSON/Markdown/comments/explanations.
    - Do not include explanations, comments, variables, outputs, or extra text.
    - Indent with exactly 2 spaces.
    """
    
    return prompt

def get_script_comparison_prompt(script1, script2) -> str:
    prompt = f"""Copmare these two terrafrom script, and tell me if they are logically correct/identical.\n 
    Script1: {script1}\n 
    Script2: {script2}\n
    Answer your question with yes or no and dont provide an explaination with more than three lines."""

    return prompt

def print_output_emission_timeElapsed(llm_output,template_output, emissions, elapsed, usage):
    print("-----This is output generated by llm/slm----\n")
    print(llm_output)
    print("------This is output template on github-----\n")
    print(template_output)
    print("")
    print("--------------This is emission--------------\n")
    print(emissions)
    print("")
    print("------------This is elapsed Time------------\n")
    print(elapsed)
    print("")
    print("----------------This is usage---------------\n")
    print(usage)
    print("")
    

def generate_result(choice, script_description, script_template, name_script):
     # Map choices to your service callables (all must be defined in service)

    initial_prompt = get_script_description_prompt(script_description)

    call_options = {
        "1": service.get_OPENAI_terraform_script,
        "2": service.get_GEMINI_terraform_script,
        "3": service.get_CLAUDE_terraform_script,
        "4": service.get_QWEN_terraform_script,
        "5": service.get_GEMMA_terraform_script,
    }

    project_name_options = {
        "1": "OpenAI",
        "2": "Gemini",
        "3": "Claude",
        "4": "Qwen",
        "5": "Gemma",
    }

    _model_call = call_options.get(choice)
    _project_name = project_name_options.get(choice)
    if _model_call is None:
        print("Invalid choice. Please run again and choose 1â€“6.")
        sys.exit(1)
    
    """
    tracking_mode:     "machine" measure the power consumptions of the entire machine (default)
                       "process" try and isolate the tracked processes in isolation
    """

    output, emissions, elapsed , usage = CodeCarbon.run_with_local_emissions(
        prompt=initial_prompt,
        model_call=_model_call,  
        tracking_mode="process",
        project_name= _project_name,
        output_dir="Output",
    )
    print("-------------------------------------------------------------------------------------------------")
    print(f'        This is Script Generation and Carbon Emission Calculation using {_project_name}'         )
    print("-------------------------------------------------------------------------------------------------")
    print_output_emission_timeElapsed(output,script_template, emissions, elapsed, usage)

    comparison_prompt = get_script_comparison_prompt(script_template, output)
    comparison = service.compare_scripts_using_open_Ai(comparison_prompt)

    print("-------------------------------------------------------------------------------------------------")
    print("             Script Quality, by comparing it with template using llm")
    print("-------------------------------------------------------------------------------------------------")
    print(comparison)



    # =========================
    # Upload artifacts to GCS
    # =========================
    ts = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
    folder = _project_name  

    # 1) Script text (HCL) from github
    script_uri = write_string_to_gcs(
        object_name=f"{ts}-script.tf",
        data=script_template,
        folder=folder,
        subfolder=name_script,
        content_type="text/plain",
    )

    # 2) Comparison result 
    comparison_uri = write_string_to_gcs(
        object_name=f"{ts}-comparison.txt",
        data=str(comparison),
        folder=folder,
        subfolder=name_script,
        content_type="text/plain",
    )

    # 3) output generated by llm

    run_uri = write_string_to_gcs(
        object_name=f"{ts}-run.json",
        data=output,
        folder=folder,
        subfolder=name_script,
        content_type="application/json",
    )

    # (Optional) 4) Upload only the last row from CodeCarbon CSV snapshot
    try:
        csv_path = Path("Output") / "emissions.csv"
        if csv_path.exists():
            lines = csv_path.read_text(encoding="utf-8").strip().splitlines()
            if len(lines) > 1:
                header = lines[0]
                last_row = lines[-1]
                # keep header + last row for clarity
                csv_text = header + "\n" + last_row
            else:
                # fallback: just one line
                csv_text = lines[0]

            cc_uri = write_string_to_gcs(
                object_name=f"{ts}-emissions.csv",
                data=csv_text,
                folder=folder,
                subfolder=name_script,
                content_type="text/csv",
            )
        else:
            cc_uri = None
    except Exception as e:
        cc_uri = None
        print(f"Warning: could not upload last-row emissions.csv: {e}")


    print("\n--- GCS Uploads ---")
    print("Script:     ", script_uri)
    print("Comparison: ", comparison_uri)
    print("Run record: ", run_uri)
    if cc_uri:
        print("CodeCarbon: ", cc_uri)


if __name__ == "__main__":
    
    name_script = "gcp"
    script_description = "Terraform module which creates VPC resources on AWS."
    script_template ="""

    module "vpc" {
    source = "terraform-aws-modules/vpc/aws"

    name = "my-vpc"
    cidr = "10.0.0.0/16"

    azs             = ["eu-west-1a", "eu-west-1b", "eu-west-1c"]
    private_subnets = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
    public_subnets  = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]

    enable_nat_gateway = true
    enable_vpn_gateway = true

    tags = {
        Terraform = "true"
        Environment = "dev"
    }
    }
    """

    choice = input(
        "\nChoose LLM:\n\n"
        "1. openai\n2. gemini\n3. claude\n\nor SLM:\n\n"
        "4. qwen\n5. gemma\nChoice: "
    ).strip()

    generate_result(choice, script_description, script_template, name_script)