# extensions/GoogleCloudStorage.py

from google.cloud import storage
from pathlib import Path
from dotenv import load_dotenv
import os
import json
from datetime import datetime
from pathlib import Path

load_dotenv()

GCS_BUCKET = os.environ.get("GCS_BUCKET")
GOOGLE_APPLICATION_CREDENTIALS = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")


#  GOOGLE CLOUD STORAGE Connection
def set_gcs_connection():
    """Return a Google Cloud Storage client using the service account key from .env."""
    creds_path = GOOGLE_APPLICATION_CREDENTIALS
    if not creds_path:
        raise RuntimeError("GOOGLE_APPLICATION_CREDENTIALS not set in .env")

    if not Path(creds_path).is_file():
        raise FileNotFoundError(f"GCP credentials file not found at: {creds_path}")
    
    client = storage.Client.from_service_account_json(str(creds_path))
    bucket = client.bucket(GCS_BUCKET)
    return bucket

def write_string_to_gcs(
    object_name: str,
    data: str,
    folder: str = None,          # top-level folder (e.g., "OpenAi")
    subfolder: str = None,       
    content_type: str = "application/json"
) -> str:
    bucket = set_gcs_connection()

    # Build object path with optional folder and subfolder
    parts = []
    if folder:
        parts.append(folder.strip("/"))
    if subfolder:
        parts.append(subfolder.strip("/"))
    parts.append(object_name)

    object_path = "/".join(parts)

    blob = bucket.blob(object_path)
    blob.upload_from_string(data, content_type=content_type)
    return f"gs://{GCS_BUCKET}/{object_path}"

def upload_to_gcs(folder, subfolder, llm_output, script_template, comparison):

    # =========================
    # Upload artifacts to GCS
    # =========================
    ts = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
    folder = folder  

    # 1) Script text (HCL) from github
    script_uri = write_string_to_gcs(
        object_name=f"{ts}-script.tf",
        data=script_template,
        folder=folder,
        subfolder=subfolder,
        content_type="text/plain",
    )

    # 2) Comparison result 
    comparison_uri = write_string_to_gcs(
        object_name=f"{ts}-comparison.txt",
        data=str(comparison),
        folder=folder,
        subfolder=subfolder,
        content_type="text/plain",
    )

    # 3) output generated by llm

    run_uri = write_string_to_gcs(
        object_name=f"{ts}-run.json",
        data=llm_output,
        folder=folder,
        subfolder=subfolder,
        content_type="application/json",
    )

    # (Optional) 4) Upload only the last row from CodeCarbon CSV snapshot
    try:
        csv_path = Path("Output") / "emissions.csv"
        if csv_path.exists():
            lines = csv_path.read_text(encoding="utf-8").strip().splitlines()
            if len(lines) > 1:
                header = lines[0]
                last_row = lines[-1]
                # keep header + last row for clarity
                csv_text = header + "\n" + last_row
            else:
                # fallback: just one line
                csv_text = lines[0]

            cc_uri = write_string_to_gcs(
                object_name=f"{ts}-emissions.csv",
                data=csv_text,
                folder=folder,
                subfolder=subfolder,
                content_type="text/csv",
            )
        else:
            cc_uri = None
    except Exception as e:
        cc_uri = None
        print(f"Warning: could not upload last-row emissions.csv: {e}")


    print("\n--- GCS Uploads ---")
    print("Script:     ", script_uri)
    print("Comparison: ", comparison_uri)
    print("Run record: ", run_uri)
    if cc_uri:
        print("CodeCarbon: ", cc_uri)

